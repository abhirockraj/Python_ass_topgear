val df_emp = spark.read.format("csv").option("header", "true").load("C:/Users/Abhinav Kumar/Desktop/wipro/spark assignment/DF/emp.txt")
val df_info = spark.read.format("csv").option("header", "true").load("C:/Users/Abhinav Kumar/Desktop/wipro/spark assignment/DF/info.txt")
val df_sinfo = spark.read.format("csv").option("header", "true").load("C:/Users/Abhinav Kumar/Desktop/wipro/spark assignment/DF/S_info.txt")
df_emp.createOrReplaceTempView("Emp")
df_info.createOrReplaceTempView("Info")
val join_e_i= spark.sql("SELECT e.Id,e.EmpName,e.Department,i.City,i.salary from Emp as e  join Info as i on e.Id=i.Id")
join_e_i.createOrReplaceTempView("join_e_i")
val q1= spark.sql("select id ,Ename,Department from join_e_i where City="Mumbai" or City="Pune"")
q1.show()
val q2=spark.sql("select * from join_e_i where salary>40000
q2.show()
val join_e_i_s=spark.sql("select j.id,j.ename,j.city,j.department,s.state from join_e_i as j join State_info as s on j.city=s.city")
join_e_i_s.createOrReplaceTempView("join_e_i_s")
val q3= spark.sql("select department from join_e_i_s where state="mh"")
q3.show()
val q4 = spark.sql("select max(salary), min(salary) from join_e_i group by department")
q4.show()
val q5= spark.sql("select avg(salary) from join_e_i group by department")
q5.show()
val q6=spark.sql("select max(salary),avg(salary),min(salary) from join_e_i group by department,state")
val q7=spark.sql("select max(salary),avg(salary),min(salary) from join_e_i group by city,state")
val q8=spark.sql("select ename from join_e_i where ename=Null")
val q9 = spark.sql("select id from join_e_i where id=null")
